# pip install google-generativeai python-dotenv

"""
CONSTRUCCI√ìN DE AGENTES EFECTIVOS CON GEMINI
Basado en: https://www.anthropic.com/engineering/building-effective-agents

PRINCIPIOS CLAVE:
1. Empezar con lo m√°s simple posible
2. Solo agregar complejidad cuando sea necesario
3. Medir el rendimiento antes de hacer m√°s complejo
4. Mantener transparencia en los pasos del agente
"""

import google.generativeai as genai
import os
from dotenv import load_dotenv
import time

# ============================================
# CONFIGURACI√ìN INICIAL
# ============================================

load_dotenv()
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# Modelo base para uso general
model = genai.GenerativeModel("models/gemini-flash-latest")


# ============================================
# EJEMPLO 1: LLM AUMENTADO (Con herramientas)
# ============================================
# Concepto: El LLM puede usar funciones externas para ampliar sus capacidades


def calculadora(operacion: str) -> dict:
    """
    Herramienta simple que realiza operaciones matem√°ticas.
    El LLM decide cu√°ndo y c√≥mo usarla.
    """
    resultado = eval(operacion)  # En producci√≥n usar ast.literal_eval o similar
    return {"resultado": resultado}


# Crear modelo con acceso a la herramienta
model_con_tools = genai.GenerativeModel(
    "models/gemini-flash-latest", tools=[calculadora]
)

# El chat con enable_automatic_function_calling=True hace que Gemini
# ejecute las funciones autom√°ticamente cuando las necesite
chat = model_con_tools.start_chat(enable_automatic_function_calling=True)

pregunta = (
    "Si tengo 15 manzanas y compro 8 paquetes de 12 manzanas cada uno, ¬øcu√°ntas tengo?"
)
response = chat.send_message(pregunta)

# La respuesta final est√° en el historial despu√©s de ejecutar las funciones
print(f"üí° Respuesta: {chat.history[-1].parts[0].text}\n")

time.sleep(2)  # Pausa por l√≠mites de API gratuita


# ============================================
# EJEMPLO 2: PROMPT CHAINING (Encadenamiento)
# ============================================
# Concepto: Dividir tareas complejas en pasos secuenciales con validaci√≥n

print("=" * 60)
print("PROMPT CHAINING: Generar contenido y traducirlo")
print("=" * 60 + "\n")

# PASO 1: Generar contenido en espa√±ol
print("üìù Paso 1: Generando contenido...")
response_1 = model.generate_content(
    "Escribe 3 p√°rrafos cortos sobre la importancia de reciclar. Hazlo motivador."
)
contenido_espanol = response_1.text
print(f"{contenido_espanol}\n")

# Validaci√≥n (gate): Verificar que el contenido es adecuado
palabras = len(contenido_espanol.split())
print(f"‚úì Verificaci√≥n: {palabras} palabras generadas")

if palabras < 50:
    print("‚ö†Ô∏è Contenido muy corto, workflow interrumpido\n")
else:
    # PASO 2: Solo continuamos si la validaci√≥n pasa
    print("\nüåç Paso 2: Traduciendo al ingl√©s...")
    response_2 = model.generate_content(
        f"Traduce al ingl√©s manteniendo el tono motivador:\n\n{contenido_espanol}"
    )
    print(f"{response_2.text}\n")
    print("‚úì Workflow completado: Generar ‚Üí Validar ‚Üí Traducir\n")

time.sleep(2)


# ============================================
# EJEMPLO 3: ROUTING (Enrutamiento)
# ============================================
# Concepto: Clasificar la entrada y dirigirla al prompt especializado correcto

print("=" * 60)
print("ROUTING: Clasificaci√≥n y respuesta especializada")
print("=" * 60 + "\n")


def procesar_consulta_soporte(consulta):
    """Clasifica la consulta y la env√≠a al especialista correcto"""

    print(f"üì© Consulta: '{consulta}'\n")

    # PASO 1: Clasificar autom√°ticamente
    response = model.generate_content(
        f"""Clasifica esta consulta en UNA categor√≠a:
        - TECNICO (errores, bugs, problemas t√©cnicos)
        - FACTURACION (pagos, facturas, cargos)
        - GENERAL (informaci√≥n general)

        Consulta: {consulta}

        Responde SOLO la categor√≠a en may√∫sculas."""
    )

    categoria = response.text.strip()
    print(f"üîç Categor√≠a: {categoria}\n")

    # PASO 2: Crear modelo con prompt especializado seg√∫n categor√≠a
    prompts = {
        "TECNICO": "Experto en soporte t√©cnico. Da soluciones paso a paso y t√©cnicas.",
        "FACTURACION": "Asistente de facturaci√≥n. S√© emp√°tico y explica claramente.",
        "GENERAL": "Asistente amigable. Responde de forma concisa y √∫til.",
    }

    instruccion = prompts.get(categoria, prompts["GENERAL"])
    model_especializado = genai.GenerativeModel(
        "models/gemini-flash-latest", system_instruction=instruccion
    )

    # PASO 3: Generar respuesta especializada
    response = model_especializado.generate_content(consulta)

    return categoria, response.text


# Probar con diferentes tipos de consultas
consultas_ejemplo = [
    "Mi app se cierra al subir fotos",
    "¬øPor qu√© me cobraron dos veces?",
    "¬øCu√°l es el horario de atenci√≥n?",
]

for consulta in consultas_ejemplo:
    print("-" * 60)
    categoria, respuesta = procesar_consulta_soporte(consulta)
    print(f"üí¨ Respuesta ({categoria}):\n{respuesta}\n")
    time.sleep(2)

time.sleep(2)


# ============================================
# EJEMPLO 4: PARALLELIZATION (Paralelizaci√≥n)
# ============================================
# Concepto: Obtener m√∫ltiples perspectivas en paralelo para mayor confianza

print("=" * 60)
print("PARALLELIZATION: M√∫ltiples perspectivas")
print("=" * 60 + "\n")

codigo_ejemplo = """
def procesar_datos(datos):
    resultado = []
    for item in datos:
        if item > 0:
            resultado.append(item * 2)
    return resultado
"""

print(f"C√≥digo a revisar:\n{codigo_ejemplo}\n")

# Crear revisiones desde 3 perspectivas diferentes
perspectivas = [
    ("üîí Seguridad", "Busca SOLO vulnerabilidades de seguridad. S√© breve."),
    ("‚ö° Performance", "Busca SOLO problemas de rendimiento. S√© breve."),
    ("üìñ Legibilidad", "Eval√∫a SOLO legibilidad y mantenibilidad. S√© breve."),
]

for nombre, enfoque in perspectivas:
    print(f"{nombre}:")
    response = model.generate_content(f"{enfoque}\n\nC√≥digo:\n{codigo_ejemplo}")
    print(f"{response.text}\n")
    time.sleep(2)

print("‚úì Revisi√≥n completa desde m√∫ltiples √°ngulos\n")
time.sleep(2)


# ============================================
# EJEMPLO 5: EVALUATOR-OPTIMIZER (Evaluador-Optimizador)
# ============================================
# Concepto: Un LLM genera, otro eval√∫a, y el primero mejora basado en feedback

print("=" * 60)
print("EVALUATOR-OPTIMIZER: Generaci√≥n iterativa mejorada")
print("=" * 60 + "\n")

tema = "el impacto de las redes sociales en los j√≥venes"

# PASO 1: Generar versi√≥n inicial
print(f"üìù Generando t√≠tulo sobre '{tema}'...")
response = model.generate_content(
    f"Crea un t√≠tulo atractivo para un art√≠culo sobre {tema}. Solo el t√≠tulo."
)
titulo_v1 = response.text.strip()
print(f"\n‚úèÔ∏è T√≠tulo v1: {titulo_v1}\n")

# PASO 2: Evaluar la primera versi√≥n
print("üîç Evaluando t√≠tulo...")
response = model.generate_content(
    f"""Eval√∫a este t√≠tulo de 1-10 considerando:
    - Claridad
    - Atractivo
    - Relevancia

    T√≠tulo: {titulo_v1}

    Formato: Puntuaci√≥n (1-10) y una sugerencia breve de mejora."""
)
evaluacion = response.text
print(f"{evaluacion}\n")

# PASO 3: Optimizar basado en la evaluaci√≥n
print("‚ú® Optimizando t√≠tulo...")
response = model.generate_content(
    f"""Mejora este t√≠tulo bas√°ndote en la evaluaci√≥n:

    T√≠tulo original: {titulo_v1}
    Evaluaci√≥n: {evaluacion}

    Dame solo el t√≠tulo mejorado, nada m√°s."""
)
titulo_v2 = response.text.strip()
print(f"\n‚úÖ T√≠tulo v2: {titulo_v2}\n")
print("‚úì Ciclo completo: Generar ‚Üí Evaluar ‚Üí Optimizar\n")

time.sleep(2)


# ============================================
# EJEMPLO 6: AGENTE AUT√ìNOMO (Con m√∫ltiples herramientas)
# ============================================
# Concepto: El agente decide qu√© herramientas usar y en qu√© orden

print("=" * 60)
print("AGENTE AUT√ìNOMO: Decisiones independientes")
print("=" * 60 + "\n")


# Definir herramientas que el agente puede usar
def buscar_informacion(tema: str) -> dict:
    """Simula b√∫squeda en base de conocimientos"""
    datos = {
        "velocidad luz": "299,792 km/s en el vac√≠o",
        "temperatura sol": "5,500¬∞C en la superficie",
        "distancia tierra luna": "384,400 km promedio",
    }
    return {"informacion": datos.get(tema.lower(), "No disponible")}


def calcular(expresion: str) -> dict:
    """Realiza c√°lculos matem√°ticos"""
    return {"resultado": eval(expresion)}


def convertir_unidades(valor: float, de: str, a: str) -> dict:
    """Convierte entre unidades comunes"""
    conversiones = {
        ("km", "millas"): valor * 0.621371,
        ("millas", "km"): valor * 1.60934,
        ("celsius", "fahrenheit"): (valor * 9 / 5) + 32,
        ("fahrenheit", "celsius"): (valor - 32) * 5 / 9,
    }
    resultado = conversiones.get((de.lower(), a.lower()))
    return (
        {"resultado": resultado, "unidad": a}
        if resultado
        else {"error": "No soportado"}
    )


# Crear agente con todas las herramientas
model_agente = genai.GenerativeModel(
    "models/gemini-flash-latest",
    tools=[buscar_informacion, calcular, convertir_unidades],
)


def ejecutar_agente(tarea):
    """
    El agente decide aut√≥nomamente qu√© herramientas usar para resolver la tarea.
    Este es el patr√≥n m√°s flexible pero tambi√©n el m√°s impredecible.
    """
    print(f"ü§ñ Tarea asignada: {tarea}\n")

    chat = model_agente.start_chat(enable_automatic_function_calling=True)
    response = chat.send_message(tarea)

    # Mostrar qu√© herramientas decidi√≥ usar el agente
    print("üîß Herramientas usadas por el agente:")
    for mensaje in chat.history[-10:]:
        for part in mensaje.parts:
            if hasattr(part, "function_call"):
                nombre = part.function_call.name
                params = (
                    dict(part.function_call.args) if part.function_call.args else {}
                )
                print(f"  ‚Ä¢ {nombre}{params}")
            if hasattr(part, "function_response"):
                resultado = dict(part.function_response.response)
                print(f"    ‚Üí {resultado}")

    print(f"\n‚úÖ Resultado final:\n{chat.history[-1].parts[0].text}\n")
    return response


# Tarea compleja que requiere m√∫ltiples pasos
tarea = """
¬øCu√°ntas millas recorre la luz en un segundo?

Necesitas:
1. Buscar la velocidad de la luz
2. Convertir de kil√≥metros a millas
"""

ejecutar_agente(tarea)


# ============================================
# RESUMEN COMPARATIVO
# ============================================

print("=" * 60)
print("CU√ÅNDO USAR CADA PATR√ìN")
print("=" * 60 + "\n")

print(
    """
üìä WORKFLOWS (Predefinidos):
   ‚úì Cu√°ndo: Los pasos son conocidos y fijos
   ‚úì Ventaja: Predecible, f√°cil de debugear, transparente
   ‚úì Ejemplo: Pipeline de contenido (generar ‚Üí revisar ‚Üí publicar)
   ‚úì Usa: Prompt Chaining, Routing, Parallelization, Evaluator-Optimizer

ü§ñ AGENTES (Aut√≥nomos):
   ‚úì Cu√°ndo: Los pasos dependen del contexto y entrada
   ‚úì Ventaja: Flexible, se adapta a situaciones inesperadas
   ‚úì Ejemplo: "Investiga X y dame un informe" (decide qu√© buscar)
   ‚úì Desventaja: Menos predecible, m√°s dif√≠cil de debugear

üí° REGLA DE ORO:
   Empieza con workflows ‚Üí Mide resultados ‚Üí Usa agentes solo si es necesario

   La mayor√≠a de problemas se resuelven mejor con workflows simples.
"""
)


# ============================================
# EJERCICIOS PROPUESTOS
# ============================================

print(
    """
EJERCICIOS PARA PRACTICAR:
==========================

1. ROUTING AVANZADO:
   Crea un clasificador de emails que categorice en:
   - URGENTE (respuesta inmediata)
   - IMPORTANTE (respuesta en 24h)
   - INFORMATIVO (solo leer)
   Y genera respuestas apropiadas seg√∫n la categor√≠a.

2. EVALUATOR-OPTIMIZER PARA C√ìDIGO:
   - LLM 1: Genera c√≥digo para resolver un problema
   - LLM 2: Eval√∫a eficiencia y legibilidad (puntaje 1-10)
   - LLM 1: Si puntaje < 8, mejora el c√≥digo
   - Repite hasta lograr puntaje ‚â• 8

3. AGENTE DE INVESTIGACI√ìN:
   Dale herramientas para:
   - buscar_informacion(tema)
   - calcular_estadisticas(datos)
   - generar_resumen(info)
   Y p√≠dele que investigue un tema y genere un reporte.

4. COMBINAR PATRONES:
   - Usa ROUTING para clasificar consultas
   - Usa CHAINING para responder en 2 pasos
   - Usa EVALUATOR para verificar calidad
   Es el ejercicio m√°s complejo pero m√°s realista.


RECURSOS:
=========
Documentaci√≥n Gemini: https://ai.google.dev/gemini-api/docs
Art√≠culo original: https://www.anthropic.com/engineering/building-effective-agents
Ejemplos: https://github.com/google-gemini/cookbook

No olvides crear .env con: GEMINI_API_KEY=tu_clave_aqui

Obt√©n tu clave en: https://aistudio.google.com/app/apikey
"""
)
